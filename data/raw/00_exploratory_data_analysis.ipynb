{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 – Exploratory Data Analysis of Source Data\n",
    "\n",
    "This notebook performs streamlined exploratory data analysis to identify data structure, cleaning requirements, and transformation needs for all raw source datasets. \n",
    "\n",
    "**Approach**: Uses helper functions to eliminate repetition and consolidate analyses into focused sections.\n",
    "\n",
    "**Datasets Analyzed**:\n",
    "1. **EDGAR Emissions Data** (Excel): 4 gas sheets (CO2, CH4, N2O, F-gas), 1990-2022, 273 NUTS2 regions\n",
    "2. **Eurostat Health Data** (TSV): Causes of Death (2011-2022) and Hospital Discharges (2000-2021)\n",
    "3. **Eurostat Population Data** (TSV): 1990-2024, 352 NUTS2 codes\n",
    "\n",
    "**Analysis Sections**:\n",
    "- **Section 1**: EDGAR emissions structure, coverage, and missing values\n",
    "- **Section 2**: Health data structure, parsing requirements, and completeness\n",
    "- **Section 3**: Population data structure and NUTS2 availability\n",
    "- **Section 4**: Geographic and temporal coverage intersection across all datasets\n",
    "- **Section 5**: Summary table and pipeline requirements\n",
    "\n",
    "**Output**: Technical requirements for ETL pipeline implementation, including data cleaning steps, transformation workflows, and harmonization window (2011-2021).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\narek.pirumyan\\Desktop\\IAE\\2025\\Big Data\\Capstone Project\\air-health-eu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "# Handle different notebook locations\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "elif PROJECT_ROOT.name == \"raw\":\n",
    "    # Notebook is in data/raw/\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.parent\n",
    "elif PROJECT_ROOT.name == \"data\":\n",
    "    # Notebook is in data/\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "elif PROJECT_ROOT.name == \"mvp\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "SRC_DIR = PROJECT_ROOT / \"mvp\" / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n",
      "Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries loaded successfully\")\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions for Data Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def check_file_info(file_path: Path) -> dict:\n",
    "    \"\"\"Check if file exists and return basic info.\"\"\"\n",
    "    if file_path.exists():\n",
    "        size_mb = file_path.stat().st_size / (1024*1024)\n",
    "        return {\"exists\": True, \"name\": file_path.name, \"size_mb\": size_mb}\n",
    "    return {\"exists\": False, \"path\": str(file_path)}\n",
    "\n",
    "def extract_year_columns_edgar(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Extract year columns from EDGAR format (Y_YYYY).\"\"\"\n",
    "    year_cols = [col for col in df.columns if col.startswith(\"Y_\")]\n",
    "    years = sorted([int(col.replace(\"Y_\", \"\")) for col in year_cols])\n",
    "    return year_cols, years\n",
    "\n",
    "def extract_year_columns_eurostat(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Extract year columns from Eurostat TSV format (YYYY with trailing space).\"\"\"\n",
    "    year_cols = [col for col in df.columns if col.strip().replace(' ', '').isdigit()]\n",
    "    years = sorted([int(col.strip()) for col in year_cols])\n",
    "    return year_cols, years\n",
    "\n",
    "def parse_eurostat_dimensions(df: pd.DataFrame, dim_col_name: str, dim_indices: dict) -> pd.DataFrame:\n",
    "    \"\"\"Parse comma-separated dimensions from Eurostat TSV first column.\"\"\"\n",
    "    df_parsed = df.copy()\n",
    "    for key, idx in dim_indices.items():\n",
    "        df_parsed[key] = df_parsed[dim_col_name].str.split(',').str[idx]\n",
    "    return df_parsed\n",
    "\n",
    "def check_data_completeness(df: pd.DataFrame, year_cols: list, years: list, n_years: int = 5) -> None:\n",
    "    \"\"\"Check data completeness for the last N years.\"\"\"\n",
    "    print(f\"\\nData completeness by year (last {n_years} years):\")\n",
    "    for year in years[-n_years:]:\n",
    "        # Find matching column (handles trailing spaces)\n",
    "        year_col = None\n",
    "        for col in year_cols:\n",
    "            if int(col.strip().replace(' ', '')) == year:\n",
    "                year_col = col\n",
    "                break\n",
    "        \n",
    "        if year_col and year_col in df.columns:\n",
    "            valid = df[year_col].apply(lambda x: pd.notna(x) and str(x).strip() != ':').sum()\n",
    "            total = len(df)\n",
    "            print(f\"  {year}: {valid}/{total} ({valid/total*100:.1f}%) valid values\")\n",
    "\n",
    "def get_nuts_level(code: str) -> str:\n",
    "    \"\"\"Determine NUTS level from code length.\"\"\"\n",
    "    if not isinstance(code, str):\n",
    "        code = str(code)\n",
    "    length = len(code.strip())\n",
    "    if length == 2:\n",
    "        return 'Country'\n",
    "    elif length == 3:\n",
    "        return 'NUTS1'\n",
    "    elif length == 4:\n",
    "        return 'NUTS2'\n",
    "    else:\n",
    "        return 'NUTS3+'\n",
    "\n",
    "print(\"Helper functions loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDGAR Emissions Data\n",
    "\n",
    "**File**: Excel workbook with 4 gas sheets (CO2, CH4, N2O, F-gas)  \n",
    "**Format**: Wide format with Y_YYYY year columns  \n",
    "**Coverage**: 1990-2022, 273 NUTS2 regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Availability Check:\n",
      "============================================================\n",
      "✓ EDGAR: EDGARv8.0_GHG_by substance_GWP100_AR5_NUTS2_1990_2022.xlsx (2.14 MB)\n",
      "✓ Causes of Death: hlth_cd_asdr2.tsv (37.20 MB)\n",
      "✓ Hospital Discharges: hlth_co_disch1t.tsv (94.75 MB)\n",
      "✓ Population: demo_r_d2jan_tabular.tsv (33.63 MB)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "edgar_path = PROJECT_ROOT / \"data\" / \"raw\" / \"emissions\" / \"EDGARv8.0_GHG_by substance_GWP100_AR5_NUTS2_1990_2022.xlsx\"\n",
    "cod_path = PROJECT_ROOT / \"data\" / \"raw\" / \"health\" / \"hlth_cd_asdr2.tsv\"\n",
    "discharge_path = PROJECT_ROOT / \"data\" / \"raw\" / \"health\" / \"hlth_co_disch1t.tsv\"\n",
    "population_path = PROJECT_ROOT / \"data\" / \"raw\" / \"population\" / \"demo_r_d2jan_tabular.tsv\"\n",
    "\n",
    "# Check all files\n",
    "print(\"File Availability Check:\")\n",
    "print(\"=\" * 60)\n",
    "for name, path in [(\"EDGAR\", edgar_path), (\"Causes of Death\", cod_path), \n",
    "                   (\"Hospital Discharges\", discharge_path), (\"Population\", population_path)]:\n",
    "    info = check_file_info(path)\n",
    "    if info[\"exists\"]:\n",
    "        print(f\"✓ {name}: {info['name']} ({info['size_mb']:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"✗ {name}: Not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EDGAR Summary by Gas Type\n",
      "============================================================\n",
      "      total_rows unique_nuts2 unique_countries unique_sectors year_range  \\\n",
      "CO2         1420          273               32              8  1990-2022   \n",
      "CH4         1505          273               32              8  1990-2022   \n",
      "N2O         1538          274               32              9  1990-2022   \n",
      "F-gas        237          237               27              1  1990-2022   \n",
      "\n",
      "      n_years  \n",
      "CO2        33  \n",
      "CH4        33  \n",
      "N2O        33  \n",
      "F-gas      33  \n",
      "\n",
      "============================================================\n",
      "Missing Values Summary (last 10 years)\n",
      "============================================================\n",
      "       missing_values  missing_pct\n",
      "CO2             132.0     0.929577\n",
      "CH4              51.0     0.338870\n",
      "N2O              70.0     0.455137\n",
      "F-gas             0.0     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive EDGAR Analysis\n",
    "if edgar_path.exists():\n",
    "    gas_sheets = {\n",
    "        \"Fossil CO2 AR5\": \"CO2\",\n",
    "        \"CH4_AR5\": \"CH4\",\n",
    "        \"N2O_AR5\": \"N2O\",\n",
    "        \"F-gas AR5\": \"F-gas\"\n",
    "    }\n",
    "    \n",
    "    edgar_summary = {}\n",
    "    missing_analysis = {}\n",
    "    \n",
    "    for sheet_name, gas_label in gas_sheets.items():\n",
    "        try:\n",
    "            # Read data (skip 5 metadata rows)\n",
    "            df = pd.read_excel(edgar_path, sheet_name=sheet_name, skiprows=5)\n",
    "            df_clean = df.dropna(subset=[\"NUTS 2\"])\n",
    "            \n",
    "            # Extract year columns\n",
    "            year_cols, years = extract_year_columns_edgar(df)\n",
    "            \n",
    "            # Summary statistics\n",
    "            edgar_summary[gas_label] = {\n",
    "                \"total_rows\": len(df),\n",
    "                \"unique_nuts2\": df_clean[\"NUTS 2\"].nunique(),\n",
    "                \"unique_countries\": df_clean[\"ISO\"].nunique(),\n",
    "                \"unique_sectors\": df_clean[\"Sector\"].nunique(),\n",
    "                \"year_range\": f\"{min(years)}-{max(years)}\",\n",
    "                \"n_years\": len(years)\n",
    "            }\n",
    "            \n",
    "            # Missing values analysis (last 10 years)\n",
    "            year_cols_recent = year_cols[-10:]\n",
    "            missing_count = sum(df[col].isna().sum() for col in year_cols_recent)\n",
    "            missing_analysis[gas_label] = {\n",
    "                \"missing_values\": missing_count,\n",
    "                \"missing_pct\": (missing_count / (len(df) * 10) * 100) if len(df) > 0 else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {gas_label}: {e}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EDGAR Summary by Gas Type\")\n",
    "    print(\"=\"*60)\n",
    "    summary_df = pd.DataFrame(edgar_summary).T\n",
    "    print(summary_df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Missing Values Summary (last 10 years)\")\n",
    "    print(\"=\"*60)\n",
    "    missing_df = pd.DataFrame(missing_analysis).T\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"EDGAR file not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings: EDGAR Data\n",
    "- **Structure**: Excel workbook, 4 gas sheets, wide format with Y_YYYY columns\n",
    "- **Metadata**: First 5 rows contain metadata (skip during read)\n",
    "- **Temporal**: 1990-2022 (33 years)\n",
    "- **Geographic**: 273 NUTS2 codes, 32 countries\n",
    "- **Missing Values**: 0.2-1.1% in recent years (concentrated in specific sectors/regions)\n",
    "- **Cleaning**: Skip metadata rows, melt year columns, standardize NUTS codes, drop null emissions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Eurostat Health Data\n",
    "\n",
    "**Files**: TSV format with comma-separated dimensions in first column  \n",
    "**Causes of Death**: 2011-2022, 491 geo codes, 93 ICD10 groups  \n",
    "**Hospital Discharges**: 2000-2021, 261 geo codes, 152 ICD10 groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Causes of Death Analysis\n",
      "============================================================\n",
      "Temporal coverage: 2011 - 2022 (12 years)\n",
      "Total rows: 398,544\n",
      "Geographic codes: 491 (NUTS2: 334)\n",
      "ICD10 groups: 93\n",
      "Respiratory ICD10 codes: ['J', 'J09-J11', 'J12-J18', 'J40-J44_J47', 'J40-J47', 'J45_J46', 'J_OTH']\n",
      "\n",
      "Data completeness by year (last 5 years):\n",
      "  2018: 364779/398544 (91.5%) valid values\n",
      "  2019: 323682/398544 (81.2%) valid values\n",
      "  2020: 336147/398544 (84.3%) valid values\n",
      "  2021: 336078/398544 (84.3%) valid values\n",
      "  2022: 332670/398544 (83.5%) valid values\n",
      "\n",
      "============================================================\n",
      "Hospital Discharges Analysis\n",
      "============================================================\n",
      "Temporal coverage: 2000 - 2021 (22 years)\n",
      "Total rows: 872,164\n",
      "Geographic codes: 261 (NUTS2: 192)\n",
      "ICD10 groups: 152\n",
      "\n",
      "Data completeness by year (last 5 years):\n",
      "  2017: 598733/872164 (68.6%) valid values\n",
      "  2018: 592948/872164 (68.0%) valid values\n",
      "  2019: 617126/872164 (70.8%) valid values\n",
      "  2020: 613964/872164 (70.4%) valid values\n",
      "  2021: 644028/872164 (73.8%) valid values\n",
      "\n",
      "============================================================\n",
      "Health Data Summary\n",
      "============================================================\n",
      "                                    file    rows      years n_years geo_codes  \\\n",
      "Causes of Death        hlth_cd_asdr2.tsv  398544  2011-2022      12       491   \n",
      "Hospital Discharges  hlth_co_disch1t.tsv  872164  2000-2021      22       261   \n",
      "\n",
      "                    icd10_groups nuts2_codes  \n",
      "Causes of Death               93         334  \n",
      "Hospital Discharges          152         192  \n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Health Data Analysis\n",
    "health_summary = {}\n",
    "\n",
    "# Causes of Death\n",
    "if cod_path.exists():\n",
    "    cod_full = pd.read_csv(cod_path, sep='\\t')\n",
    "    dim_col = [col for col in cod_full.columns if 'geo' in col.lower() and 'TIME_PERIOD' in col]\n",
    "    \n",
    "    if dim_col:\n",
    "        dim_col_name = dim_col[0]\n",
    "        # Parse dimensions: freq,unit,sex,age,icd10,geo\\TIME_PERIOD\n",
    "        cod_full = parse_eurostat_dimensions(cod_full, dim_col_name, {\n",
    "            'freq': 0, 'unit': 1, 'sex': 2, 'age': 3, 'icd10': 4, 'geo': 5\n",
    "        })\n",
    "        \n",
    "        year_cols, years = extract_year_columns_eurostat(cod_full)\n",
    "        \n",
    "        health_summary['Causes of Death'] = {\n",
    "            'file': cod_path.name,\n",
    "            'rows': len(cod_full),\n",
    "            'years': f\"{min(years)}-{max(years)}\",\n",
    "            'n_years': len(years),\n",
    "            'geo_codes': cod_full['geo'].nunique(),\n",
    "            'icd10_groups': cod_full['icd10'].nunique(),\n",
    "            'nuts2_codes': cod_full[cod_full['geo'].str.len() == 4]['geo'].nunique()\n",
    "        }\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"Causes of Death Analysis\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Temporal coverage: {min(years)} - {max(years)} ({len(years)} years)\")\n",
    "        print(f\"Total rows: {len(cod_full):,}\")\n",
    "        print(f\"Geographic codes: {cod_full['geo'].nunique()} (NUTS2: {health_summary['Causes of Death']['nuts2_codes']})\")\n",
    "        print(f\"ICD10 groups: {cod_full['icd10'].nunique()}\")\n",
    "        \n",
    "        # Respiratory codes\n",
    "        resp_codes = [c for c in cod_full['icd10'].unique() \n",
    "                     if isinstance(c, str) and (c.startswith('J') or 'resp' in c.lower())]\n",
    "        print(f\"Respiratory ICD10 codes: {resp_codes}\")\n",
    "        \n",
    "        check_data_completeness(cod_full, year_cols, years, n_years=5)\n",
    "\n",
    "# Hospital Discharges\n",
    "if discharge_path.exists():\n",
    "    discharge_full = pd.read_csv(discharge_path, sep='\\t')\n",
    "    dim_col = [col for col in discharge_full.columns if 'geo' in col.lower() and 'TIME_PERIOD' in col]\n",
    "    \n",
    "    if dim_col:\n",
    "        dim_col_name = dim_col[0]\n",
    "        # Parse dimensions: freq,age,indic_he,unit,sex,icd10,geo\\TIME_PERIOD\n",
    "        discharge_full = parse_eurostat_dimensions(discharge_full, dim_col_name, {\n",
    "            'freq': 0, 'age': 1, 'indic_he': 2, 'unit': 3, 'sex': 4, 'icd10': 5, 'geo': 6\n",
    "        })\n",
    "        \n",
    "        year_cols, years = extract_year_columns_eurostat(discharge_full)\n",
    "        \n",
    "        health_summary['Hospital Discharges'] = {\n",
    "            'file': discharge_path.name,\n",
    "            'rows': len(discharge_full),\n",
    "            'years': f\"{min(years)}-{max(years)}\",\n",
    "            'n_years': len(years),\n",
    "            'geo_codes': discharge_full['geo'].nunique(),\n",
    "            'icd10_groups': discharge_full['icd10'].nunique(),\n",
    "            'nuts2_codes': discharge_full[discharge_full['geo'].str.len() == 4]['geo'].nunique()\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Hospital Discharges Analysis\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Temporal coverage: {min(years)} - {max(years)} ({len(years)} years)\")\n",
    "        print(f\"Total rows: {len(discharge_full):,}\")\n",
    "        print(f\"Geographic codes: {discharge_full['geo'].nunique()} (NUTS2: {health_summary['Hospital Discharges']['nuts2_codes']})\")\n",
    "        print(f\"ICD10 groups: {discharge_full['icd10'].nunique()}\")\n",
    "        \n",
    "        check_data_completeness(discharge_full, year_cols, years, n_years=5)\n",
    "\n",
    "# Summary\n",
    "if health_summary:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Health Data Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(pd.DataFrame(health_summary).T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings: Health Data\n",
    "- **Format**: TSV with comma-separated dimensions in first column\n",
    "- **Parsing**: Split first column by comma, extract geo code (index 5 for COD, 6 for discharges)\n",
    "- **Year Columns**: Named as `YYYY ` (with trailing space) - need `.strip()` before conversion\n",
    "- **Missing Data**: `:` indicator - replace with `pd.NA` before numeric conversion\n",
    "- **Completeness**: 83-100% depending on dataset and year\n",
    "- **Cleaning**: Parse dimensions → Melt → Handle missing (`:`) → Standardize geo codes → Filter dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Population Data\n",
    "\n",
    "**File**: TSV format (demo_r_d2jan_tabular.tsv)  \n",
    "**Format**: Same as health data - comma-separated dimensions  \n",
    "**Coverage**: 1990-2024, 521 geo codes (352 NUTS2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Population Data Analysis\n",
      "============================================================\n",
      "Temporal coverage: 1990 - 2024 (35 years)\n",
      "Total rows: 160,575\n",
      "Geographic codes: 521\n",
      "\n",
      "Geographic level distribution:\n",
      "nuts_level\n",
      "NUTS2      108540\n",
      "NUTS1       39768\n",
      "Country     11388\n",
      "NUTS3+        879\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NUTS2 codes: 352 unique codes\n",
      "\n",
      "Data completeness by year (last 5 years):\n",
      "  2020: 138539/160575 (86.3%) valid values\n",
      "  2021: 136823/160575 (85.2%) valid values\n",
      "  2022: 135702/160575 (84.5%) valid values\n",
      "  2023: 138078/160575 (86.0%) valid values\n",
      "  2024: 135117/160575 (84.1%) valid values\n",
      "\n",
      "NUTS2 data availability (freq=A, unit=NR, sex=T, age=TOTAL):\n",
      "  Filtered rows: 352\n",
      "  2020: 303/352 (86.1%) valid\n",
      "  2021: 293/352 (83.2%) valid\n",
      "  2022: 294/352 (83.5%) valid\n",
      "  2023: 298/352 (84.7%) valid\n",
      "  2024: 292/352 (83.0%) valid\n"
     ]
    }
   ],
   "source": [
    "# Population Data Analysis\n",
    "if population_path.exists():\n",
    "    population_full = pd.read_csv(population_path, sep='\\t')\n",
    "    \n",
    "    # Parse dimensions: freq,unit,sex,age,geo\\TIME_PERIOD\n",
    "    dim_col = population_full.columns[0]\n",
    "    population_full = parse_eurostat_dimensions(population_full, dim_col, {\n",
    "        'freq': 0, 'unit': 1, 'sex': 2, 'age': 3, 'geo': 4\n",
    "    })\n",
    "    \n",
    "    year_cols, years = extract_year_columns_eurostat(population_full)\n",
    "    \n",
    "    # Geographic level distribution\n",
    "    population_full['nuts_level'] = population_full['geo'].apply(get_nuts_level)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Population Data Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Temporal coverage: {min(years)} - {max(years)} ({len(years)} years)\")\n",
    "    print(f\"Total rows: {len(population_full):,}\")\n",
    "    print(f\"Geographic codes: {population_full['geo'].nunique()}\")\n",
    "    print(f\"\\nGeographic level distribution:\")\n",
    "    print(population_full['nuts_level'].value_counts())\n",
    "    \n",
    "    nuts2_count = population_full[population_full['nuts_level'] == 'NUTS2']['geo'].nunique()\n",
    "    print(f\"\\nNUTS2 codes: {nuts2_count} unique codes\")\n",
    "    \n",
    "    # Data completeness\n",
    "    check_data_completeness(population_full, year_cols, years, n_years=5)\n",
    "    \n",
    "    # NUTS2 availability (filtered to standard dimensions)\n",
    "    filtered = population_full[\n",
    "        (population_full['freq'] == 'A') & \n",
    "        (population_full['unit'] == 'NR') & \n",
    "        (population_full['sex'] == 'T') & \n",
    "        (population_full['age'] == 'TOTAL') &\n",
    "        (population_full['nuts_level'] == 'NUTS2')\n",
    "    ]\n",
    "    \n",
    "    if len(filtered) > 0:\n",
    "        print(f\"\\nNUTS2 data availability (freq=A, unit=NR, sex=T, age=TOTAL):\")\n",
    "        print(f\"  Filtered rows: {len(filtered)}\")\n",
    "        for year in years[-5:]:\n",
    "            year_col = None\n",
    "            for col in year_cols:\n",
    "                if int(col.strip()) == year:\n",
    "                    year_col = col\n",
    "                    break\n",
    "            if year_col:\n",
    "                valid = filtered[year_col].apply(lambda x: pd.notna(x) and str(x).strip() != ':').sum()\n",
    "                total = len(filtered)\n",
    "                print(f\"  {year}: {valid}/{total} ({valid/total*100:.1f}%) valid\")\n",
    "else:\n",
    "    print(\"Population file not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings: Population Data\n",
    "- **Format**: Same TSV structure as health data\n",
    "- **Dimensions**: freq,unit,sex,age,geo\\TIME_PERIOD\n",
    "- **Coverage**: 1990-2024 (35 years), 352 NUTS2 codes\n",
    "- **Completeness**: 83-86% for recent years at NUTS2 level\n",
    "- **Cleaning**: Same as health data - parse dimensions, melt, handle missing, standardize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geographic & Temporal Coverage\n",
    "\n",
    "**Geographic**: Compare NUTS2 coverage across datasets  \n",
    "**Temporal**: Find intersection of available years for harmonization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Findings: EDGAR Data Structure & Cleaning Requirements\n",
    "\n",
    "**Data Structure:**\n",
    "- **Metadata Rows**: First 5 rows contain metadata (Content, Compound, Start year, End year) - must be skipped during read\n",
    "- **Column Format**: Year columns use `Y_YYYY` format (e.g., `Y_1990`, `Y_2022`) - requires string replacement to extract year integer\n",
    "- **Wide Format**: Data is in wide format with year columns - requires melt operation to convert to tidy format\n",
    "- **NUTS2 desc**: Contains region names, some rows have null values - this is expected and indicates country-level emissions that cannot be assigned to a specific NUTS2 region (e.g., domestic aviation, domestic shipping)\n",
    "\n",
    "**Data Cleaning Requirements:**\n",
    "- **NUTS2 Standardization**: Codes need `.str.strip().str.upper()` to ensure consistent formatting for joins\n",
    "- **Country ISO Codes**: Need `.str.strip().str.upper()` for consistency\n",
    "- **Missing Values in Emission Columns**: \n",
    "  - **Pattern**: Small percentage (0.9-1.1%) of missing values in recent years (2018-2022)\n",
    "  - **Cause**: Likely due to data collection gaps, reporting delays, or sectors/regions with incomplete reporting\n",
    "  - **Distribution**: Missing values may be concentrated in specific sectors or geographic levels (country vs NUTS2)\n",
    "  - **Handling Strategy**: Drop rows with missing emission values using `.dropna(subset=[\"emissions_kt_co2e\"])` after melt operation\n",
    "- **NUTS2 desc Missing Values**: \n",
    "  - **Expected Behavior**: Null values occur when `NUTS 2` code is a 2-character country code (e.g., \"AT\" for Austria)\n",
    "  - **Handling**: No action needed - these represent country-level aggregations and should be preserved. Country-level rows should be kept for completeness, but may need separate handling in NUTS2-specific analyses\n",
    "- **Sector Mapping**: Need to map detailed sectors to high-level groups (Industry, Buildings, Transport, Energy, Agriculture, Waste, other)\n",
    "\n",
    "**Transformation Requirements:**\n",
    "- Melt year columns: `id_vars` = [Substance, ISO, Country, NUTS 2, NUTS 2 desc, Sector], `value_vars` = all Y_* columns\n",
    "- Rename columns: Substance→gas, ISO→country_iso, Country→country_name, NUTS 2→nuts_id, NUTS 2 desc→nuts_label\n",
    "- Extract year: Convert `Y_2022` → `2022` (integer)\n",
    "- Combine sheets: Concatenate all gas sheets (CO2, CH4, N2O, F-gas) into single dataframe\n",
    "- Sector grouping: Apply mapping dictionary to create `sector_group` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NUTS2 Geographic Coverage\n",
      "============================================================\n",
      "EDGAR: 273 unique NUTS2 codes\n",
      "Causes of Death: 334 unique NUTS2 codes\n",
      "Hospital Discharges: 192 unique NUTS2 codes\n",
      "Population: 352 unique NUTS2 codes\n",
      "\n",
      "Total unique NUTS2 codes across all datasets: 416\n",
      "NUTS2 codes in both EDGAR and Causes of Death: 242\n",
      "\n",
      "============================================================\n",
      "Temporal Coverage Intersection\n",
      "============================================================\n",
      "EDGAR: 1990 - 2022 (33 years)\n",
      "Causes of Death: 2011 - 2022 (12 years)\n",
      "Hospital Discharges: 2000 - 2021 (22 years)\n",
      "Population: 1990 - 2024 (35 years)\n",
      "\n",
      "✓ Harmonization window: 2011 - 2021 (11 years)\n",
      "  Years: [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
      "\n",
      "EDGAR ∩ Causes of Death: 2011 - 2022 (12 years)\n"
     ]
    }
   ],
   "source": [
    "# Geographic Coverage Comparison\n",
    "nuts2_coverage = {}\n",
    "\n",
    "# EDGAR\n",
    "if edgar_path.exists():\n",
    "    df_co2 = pd.read_excel(edgar_path, sheet_name=\"Fossil CO2 AR5\", skiprows=5)\n",
    "    df_co2 = df_co2.dropna(subset=[\"NUTS 2\"])\n",
    "    edgar_nuts2 = set(df_co2[\"NUTS 2\"].str.strip().str.upper().unique())\n",
    "    nuts2_coverage['EDGAR'] = edgar_nuts2\n",
    "\n",
    "# Health data\n",
    "if cod_path.exists():\n",
    "    cod_full = pd.read_csv(cod_path, sep='\\t')\n",
    "    dim_col = [col for col in cod_full.columns if 'geo' in col.lower() and 'TIME_PERIOD' in col]\n",
    "    if dim_col:\n",
    "        cod_full['geo'] = cod_full[dim_col[0]].str.split(',').str[5]\n",
    "        cod_nuts2 = {g.strip().upper() for g in cod_full['geo'].unique() if isinstance(g, str) and len(str(g).strip()) == 4}\n",
    "        nuts2_coverage['Causes of Death'] = cod_nuts2\n",
    "\n",
    "if discharge_path.exists():\n",
    "    discharge_full = pd.read_csv(discharge_path, sep='\\t')\n",
    "    dim_col = [col for col in discharge_full.columns if 'geo' in col.lower() and 'TIME_PERIOD' in col]\n",
    "    if dim_col:\n",
    "        discharge_full['geo'] = discharge_full[dim_col[0]].str.split(',').str[6]\n",
    "        discharge_nuts2 = {g.strip().upper() for g in discharge_full['geo'].unique() if isinstance(g, str) and len(str(g).strip()) == 4}\n",
    "        nuts2_coverage['Hospital Discharges'] = discharge_nuts2\n",
    "\n",
    "# Population\n",
    "if population_path.exists():\n",
    "    pop_full = pd.read_csv(population_path, sep='\\t')\n",
    "    dim_col = pop_full.columns[0]\n",
    "    pop_full['geo'] = pop_full[dim_col].str.split(',').str[4]\n",
    "    pop_nuts2 = {g.strip().upper() for g in pop_full['geo'].unique() if isinstance(g, str) and len(str(g).strip()) == 4}\n",
    "    nuts2_coverage['Population'] = pop_nuts2\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"NUTS2 Geographic Coverage\")\n",
    "print(\"=\"*60)\n",
    "for name, codes in nuts2_coverage.items():\n",
    "    print(f\"{name}: {len(codes)} unique NUTS2 codes\")\n",
    "\n",
    "if len(nuts2_coverage) >= 2:\n",
    "    all_nuts2 = set.union(*nuts2_coverage.values())\n",
    "    print(f\"\\nTotal unique NUTS2 codes across all datasets: {len(all_nuts2)}\")\n",
    "    \n",
    "    if 'EDGAR' in nuts2_coverage and 'Causes of Death' in nuts2_coverage:\n",
    "        intersection = nuts2_coverage['EDGAR'] & nuts2_coverage['Causes of Death']\n",
    "        print(f\"NUTS2 codes in both EDGAR and Causes of Death: {len(intersection)}\")\n",
    "\n",
    "# Temporal Coverage Intersection\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Temporal Coverage Intersection\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "temporal_coverage = {}\n",
    "\n",
    "# EDGAR\n",
    "if edgar_path.exists():\n",
    "    df_co2 = pd.read_excel(edgar_path, sheet_name=\"Fossil CO2 AR5\", skiprows=5)\n",
    "    _, edgar_years = extract_year_columns_edgar(df_co2)\n",
    "    temporal_coverage['EDGAR'] = set(edgar_years)\n",
    "    print(f\"EDGAR: {min(edgar_years)} - {max(edgar_years)} ({len(edgar_years)} years)\")\n",
    "\n",
    "# Causes of Death\n",
    "if cod_path.exists():\n",
    "    cod_full = pd.read_csv(cod_path, sep='\\t')\n",
    "    _, cod_years = extract_year_columns_eurostat(cod_full)\n",
    "    temporal_coverage['Causes of Death'] = set(cod_years)\n",
    "    print(f\"Causes of Death: {min(cod_years)} - {max(cod_years)} ({len(cod_years)} years)\")\n",
    "\n",
    "# Hospital Discharges\n",
    "if discharge_path.exists():\n",
    "    discharge_full = pd.read_csv(discharge_path, sep='\\t')\n",
    "    _, discharge_years = extract_year_columns_eurostat(discharge_full)\n",
    "    temporal_coverage['Hospital Discharges'] = set(discharge_years)\n",
    "    print(f\"Hospital Discharges: {min(discharge_years)} - {max(discharge_years)} ({len(discharge_years)} years)\")\n",
    "\n",
    "# Population\n",
    "if population_path.exists():\n",
    "    pop_full = pd.read_csv(population_path, sep='\\t')\n",
    "    _, pop_years = extract_year_columns_eurostat(pop_full)\n",
    "    temporal_coverage['Population'] = set(pop_years)\n",
    "    print(f\"Population: {min(pop_years)} - {max(pop_years)} ({len(pop_years)} years)\")\n",
    "\n",
    "# Find intersection\n",
    "if len(temporal_coverage) >= 2:\n",
    "    intersection_years = set.intersection(*temporal_coverage.values())\n",
    "    if intersection_years:\n",
    "        print(f\"\\n✓ Harmonization window: {min(intersection_years)} - {max(intersection_years)} ({len(intersection_years)} years)\")\n",
    "        print(f\"  Years: {sorted(intersection_years)}\")\n",
    "    else:\n",
    "        print(\"\\n⚠ No complete intersection - use pairwise intersections\")\n",
    "        \n",
    "    if 'EDGAR' in temporal_coverage and 'Causes of Death' in temporal_coverage:\n",
    "        edgar_cod = temporal_coverage['EDGAR'] & temporal_coverage['Causes of Death']\n",
    "        if edgar_cod:\n",
    "            print(f\"\\nEDGAR ∩ Causes of Death: {min(edgar_cod)} - {max(edgar_cod)} ({len(edgar_cod)} years)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary & Pipeline Requirements\n",
    "\n",
    "### Dataset Structure\n",
    "\n",
    "| Dataset | Format | Years | NUTS2 Codes | Key Features |\n",
    "|---------|--------|------|-------------|--------------|\n",
    "| **EDGAR** | Excel (4 sheets) | 1990-2022 | 273 | Wide format, Y_YYYY columns, skip 5 metadata rows |\n",
    "| **Causes of Death** | TSV | 2011-2022 | 334 | Comma-separated dimensions, 93 ICD10 groups |\n",
    "| **Hospital Discharges** | TSV | 2000-2021 | 192 | Same format, 152 ICD10 groups |\n",
    "| **Population** | TSV | 1990-2024 | 352 | Same format, multiple age/sex dimensions |\n",
    "\n",
    "### Harmonization Window\n",
    "**✓ 2011-2021 (11 years)** - Complete coverage across all datasets\n",
    "\n",
    "### Data Cleaning Requirements\n",
    "\n",
    "**EDGAR:**\n",
    "- Skip first 5 metadata rows\n",
    "- Melt Y_YYYY columns to long format\n",
    "- Standardize: `.str.strip().str.upper()` for NUTS codes\n",
    "- Drop null emissions (0.2-1.1% missing)\n",
    "\n",
    "**Health & Population (TSV):**\n",
    "- Parse comma-separated dimensions from first column\n",
    "- Melt year columns (handle trailing spaces)\n",
    "- Replace `:` with `pd.NA` before numeric conversion\n",
    "- Filter to: `freq='A'`, `sex='T'`, `age='TOTAL'` (for population)\n",
    "- Standardize geo codes: `.str.strip().str.upper()`\n",
    "\n",
    "### Transformation Pipeline\n",
    "\n",
    "1. **EDGAR**: Read Excel → Skip metadata → Melt → Standardize → Combine sheets\n",
    "2. **Health**: Read TSV → Parse dimensions → Melt → Clean missing → Standardize → Filter\n",
    "3. **Population**: Read TSV → Parse dimensions → Melt → Clean missing → Standardize → Filter\n",
    "4. **Harmonization**: Filter to 2011-2021 → Merge on `nuts_id` + `year` → Calculate derived metrics\n",
    "5. **Output**: Save to Parquet format\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
