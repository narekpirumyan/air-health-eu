{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 – Load Population Data\n",
        "\n",
        "This notebook processes population data from Eurostat TSV file or downloads from API.\n",
        "\n",
        "**What this step does:**\n",
        "- **Primary**: Processes TSV file from `data/raw/population/demo_r_d2jan_tabular.tsv` (if available)\n",
        "- **Fallback**: Downloads population data from Eurostat API (dataset `demo_r_pjangrp3` or alternatives)\n",
        "- **Preserves all geographic levels**: Keeps country (2 chars), NUTS1 (3 chars), NUTS2 (4 chars), and NUTS3 (5+ chars) codes\n",
        "- **Year range**: Processes data for 1990-2024 from TSV file, or downloads available years from API\n",
        "- Caches the data to `data/processed/population_nuts2.parquet` for reuse\n",
        "\n",
        "**Note**: All geographic levels are preserved for maximum flexibility in the star schema. Filtering to specific NUTS levels can be done during ETL or in queries.\n",
        "\n",
        "**Shared utility**: This population data is used by both MVP (for curated dataset) and production (for database loading).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WindowsPath('C:/Users/narek.pirumyan/Desktop/IAE/2025/Big Data/Capstone Project/air-health-eu')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from eurostat import get_data_df\n",
        "import requests\n",
        "import io\n",
        "\n",
        "# Setup paths\n",
        "PROJECT_ROOT = Path.cwd().resolve()\n",
        "if PROJECT_ROOT.name == \"notebooks\":\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "\n",
        "PROJECT_ROOT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _tidy_eurostat_population_tsv(path: Path, filter_nuts2: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert Eurostat population TSV into a tidy dataframe.\n",
        "    Similar to _tidy_eurostat_tsv but specifically for population data.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, sep=\"\\t\")\n",
        "    dimension_col = df.columns[0]\n",
        "    dimension_names = dimension_col.split(\",\")\n",
        "    dims = df[dimension_col].str.split(\",\", expand=True)\n",
        "    dims.columns = dimension_names\n",
        "\n",
        "    wide_values = df.drop(columns=[dimension_col])\n",
        "    tidy = pd.concat([dims, wide_values], axis=1)\n",
        "    year_columns = [c for c in wide_values.columns if c.strip().replace(' ', '').isdigit()]\n",
        "\n",
        "    tidy = tidy.melt(\n",
        "        id_vars=dimension_names,\n",
        "        value_vars=year_columns,\n",
        "        var_name=\"year\",\n",
        "        value_name=\"population\",\n",
        "    )\n",
        "\n",
        "    tidy[\"year\"] = tidy[\"year\"].astype(str).str.strip().astype(int)\n",
        "    tidy[\"population\"] = (\n",
        "        tidy[\"population\"]\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .replace(\":\", pd.NA)\n",
        "    )\n",
        "    tidy[\"population\"] = pd.to_numeric(tidy[\"population\"], errors=\"coerce\")\n",
        "\n",
        "    # Handle geo column (may be named 'geo' or 'geo\\TIME_PERIOD')\n",
        "    geo_col = None\n",
        "    for col_name in tidy.columns:\n",
        "        if 'geo' in col_name.lower() and 'time_period' in col_name.lower():\n",
        "            geo_col = col_name\n",
        "            break\n",
        "    if not geo_col and 'geo' in tidy.columns:\n",
        "        geo_col = 'geo'\n",
        "\n",
        "    if geo_col:\n",
        "        tidy[\"geo\"] = tidy[geo_col].str.strip().str.upper()\n",
        "        # Optional: Filter to NUTS2 level only (4 characters) if requested\n",
        "        if filter_nuts2:\n",
        "            def _is_valid_nuts2(code: str) -> bool:\n",
        "                if not isinstance(code, str):\n",
        "                    code = str(code)\n",
        "                return len(code.strip()) == 4\n",
        "            tidy = tidy[tidy[\"geo\"].apply(_is_valid_nuts2)].copy()\n",
        "        if geo_col != \"geo\" and geo_col in tidy.columns:\n",
        "            tidy = tidy.drop(columns=[geo_col])\n",
        "    \n",
        "    # Filter to standard dimensions: freq=A, unit=NR, sex=T, age=TOTAL\n",
        "    if 'freq' in tidy.columns:\n",
        "        tidy = tidy[tidy['freq'] == 'A']\n",
        "    if 'unit' in tidy.columns:\n",
        "        tidy = tidy[tidy['unit'] == 'NR']\n",
        "    if 'sex' in tidy.columns:\n",
        "        tidy = tidy[tidy['sex'] == 'T']\n",
        "    if 'age' in tidy.columns:\n",
        "        tidy = tidy[tidy['age'] == 'TOTAL']\n",
        "    \n",
        "    # Keep only essential columns\n",
        "    tidy = tidy[['geo', 'year', 'population']].dropna(subset=['population'])\n",
        "    \n",
        "    return tidy\n",
        "\n",
        "\n",
        "def _process_population_tsv(tsv_path: Path, filter_nuts2: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process population TSV file from data/raw/population.\n",
        "    \n",
        "    Parameters:\n",
        "    - tsv_path: Path to the TSV file\n",
        "    - filter_nuts2: If True, filter to NUTS2 level only\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame with columns: geo, year, population\n",
        "    \"\"\"\n",
        "    if not tsv_path.exists():\n",
        "        raise FileNotFoundError(f\"Population TSV file not found: {tsv_path}\")\n",
        "    \n",
        "    print(f\"  Processing TSV file: {tsv_path.name}\")\n",
        "    tidy = _tidy_eurostat_population_tsv(tsv_path, filter_nuts2=filter_nuts2)\n",
        "    \n",
        "    years = sorted(tidy['year'].unique())\n",
        "    print(f\"    ✓ Processed: years {min(years)}-{max(years)}, {len(tidy)} records\")\n",
        "    print(f\"    ✓ Unique geographic codes: {tidy['geo'].nunique()}\")\n",
        "    \n",
        "    return tidy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Loaded 14,830 population records\n",
            "  Years: 1990 - 2024\n",
            "  Unique geographic codes: 521\n",
            "  Geographic code length distribution:\n",
            "    {2: 1228, 3: 3793, 4: 9768, 6: 15, 9: 26}\n",
            "\n",
            "  NUTS2 data available for years: 1990 - 2024 (35 years)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geo</th>\n",
              "      <th>year</th>\n",
              "      <th>population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AL</td>\n",
              "      <td>1990</td>\n",
              "      <td>3286500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AL0</td>\n",
              "      <td>1990</td>\n",
              "      <td>3286500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AT</td>\n",
              "      <td>1990</td>\n",
              "      <td>7644818.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AT1</td>\n",
              "      <td>1990</td>\n",
              "      <td>3219274.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AT11</td>\n",
              "      <td>1990</td>\n",
              "      <td>270670.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    geo  year  population\n",
              "0    AL  1990   3286500.0\n",
              "1   AL0  1990   3286500.0\n",
              "2    AT  1990   7644818.0\n",
              "3   AT1  1990   3219274.0\n",
              "4  AT11  1990    270670.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _download_demo_r_d2jan() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Download population data from demo_r_d2jan dataset using SDMX API.\n",
        "    This dataset may have historical NUTS2 data going back to 2000.\n",
        "    Tries both TSV and CSV formats.\n",
        "    \"\"\"\n",
        "    import requests\n",
        "    import io\n",
        "    \n",
        "    # Try CSV format first (easier to parse, includes labels)\n",
        "    csv_url = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/3.0/data/dataflow/ESTAT/demo_r_d2jan/1.0\"\n",
        "    csv_params = {\n",
        "        'compress': 'true',\n",
        "        'format': 'csvdata',\n",
        "        'formatVersion': '2.0',\n",
        "        'lang': 'en',\n",
        "        'labels': 'both'\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        print(\"  Downloading from demo_r_d2jan (SDMX API - CSV format)...\")\n",
        "        response = requests.get(csv_url, params=csv_params, timeout=120)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        # Read CSV data\n",
        "        df = pd.read_csv(io.StringIO(response.text), low_memory=False)\n",
        "        \n",
        "        # CSV format with labels should have columns like: freq, unit, sex, age, geo, TIME_PERIOD, OBS_VALUE\n",
        "        # Or it might be in a different structure - let's check the columns\n",
        "        print(f\"    CSV columns: {list(df.columns)[:10]}...\")  # Debug info\n",
        "        \n",
        "        # Look for common column patterns\n",
        "        if 'TIME_PERIOD' in df.columns and 'OBS_VALUE' in df.columns:\n",
        "            # Standard SDMX CSV format\n",
        "            tidy = df[\n",
        "                (df.get('freq', '') == 'A') &\n",
        "                (df.get('unit', '') == 'NR') &\n",
        "                (df.get('sex', '') == 'T') &\n",
        "                (df.get('age', '') == 'TOTAL')\n",
        "            ].copy()\n",
        "            \n",
        "            if not tidy.empty:\n",
        "                tidy = tidy.rename(columns={'TIME_PERIOD': 'year', 'OBS_VALUE': 'population'})\n",
        "                tidy['year'] = tidy['year'].astype(int)\n",
        "                tidy['geo'] = tidy['geo'].str.strip().str.upper()\n",
        "                tidy['population'] = pd.to_numeric(tidy['population'], errors='coerce')\n",
        "                tidy = tidy.dropna(subset=['population'])\n",
        "                tidy = tidy[(tidy['year'] >= 2000) & (tidy['year'] <= 2024)]\n",
        "                return tidy[['geo', 'year', 'population']]\n",
        "        \n",
        "        # If CSV format doesn't work, try TSV format with filters\n",
        "        print(\"    CSV format not as expected, trying TSV format with filters...\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"    CSV format failed: {e}, trying TSV format...\")\n",
        "    \n",
        "    # Fallback to TSV format with specific filters\n",
        "    tsv_url = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/3.0/data/dataflow/ESTAT/demo_r_d2jan/1.0/*.*.*.*.*\"\n",
        "    tsv_params = {\n",
        "        'c[freq]': 'A',\n",
        "        'c[unit]': 'NR',\n",
        "        'c[sex]': 'T',\n",
        "        'c[age]': 'TOTAL',\n",
        "        'c[geo]': 'EU27_2020,EU28,EU27_2007,BE,BE1,BE10,BE2,BE21,BE22,BE23,BE24,BE25,BE3,BE31,BE32,BE33,BE34,BE35,BG,BG3,BG31,BG32,BG33,BG34,BG4,BG41,BG42,CZ,CZ0,CZ01,CZ02,CZ03,CZ04,CZ05,CZ06,CZ07,CZ08,DK,DK0,DK01,DK02,DK03,DK04,DK05,DE,DE_TOT,DE1,DE11,DE12,DE13,DE14,DE2,DE21,DE22,DE23,DE24,DE25,DE26,DE27,DE3,DE30,DE4,DE40,DE5,DE50,DE6,DE60,DE7,DE71,DE72,DE73,DE8,DE80,DE9,DE91,DE92,DE93,DE94,DEA,DEA1,DEA2,DEA3,DEA4,DEA5,DEB,DEB1,DEB2,DEB3,DEC,DEC0,DED,DED2,DED4,DED5,DEE,DEE0,DEF,DEF0,DEG,DEG0,EE,EE0,EE00,IE,IE0,IE04,IE05,IE06,EL,EL3,EL30,EL4,EL41,EL42,EL43,EL5,EL51,EL52,EL53,EL54,EL6,EL61,EL62,EL63,EL64,EL65,ES,ES1,ES11,ES12,ES13,ES2,ES21,ES22,ES23,ES24,ES3,ES30,ES4,ES41,ES42,ES43,ES5,ES51,ES52,ES53,ES6,ES61,ES62,ES63,ES64,ES7,ES70,FR,FR1,FR10,FRB,FRB0,FRC,FRC1,FRC2,FRD,FRD1,FRD2,FRE,FRE1,FRE2,FRF,FRF1,FRF2,FRF3,FRG,FRG0,FRH,FRH0,FRI,FRI1,FRI2,FRI3,FRJ,FRJ1,FRJ2,FRK,FRK1,FRK2,FRL,FRL0,FRM,FRM0,FRY,FRY1,FRY2,FRY3,FRY4,FRY5,FRX,FRXX,HR,HR0,HR02,HR03,HR04,HR05,HR06,IT,ITC,ITC1,ITC2,ITC3,ITC4,ITF,ITF1,ITF2,ITF3,ITF4,ITF5,ITF6,ITG,ITG1,ITG2,ITH,ITH1,ITH2,ITH3,ITH4,ITH5,ITI,ITI1,ITI2,ITI3,ITI4,CY,CY0,CY00,LV,LV0,LV00,LT,LT0,LT01,LT02,LU,LU0,LU00,HU,HU1,HU11,HU12,HU2,HU21,HU22,HU23,HU3,HU31,HU32,HU33,HUX,HUXX,MT,MT0,MT00,NL,NL1,NL11,NL12,NL13,NL2,NL21,NL22,NL23,NL3,NL31,NL32,NL33,NL34,NL35,NL36,NL4,NL41,NL42,AT,AT1,AT11,AT12,AT13,AT2,AT21,AT22,AT3,AT31,AT32,AT33,AT34,PL,PL2,PL21,PL22,PL4,PL41,PL42,PL43,PL5,PL51,PL52,PL6,PL61,PL62,PL63,PL7,PL71,PL72,PL8,PL81,PL82,PL84,PL9,PL91,PL92,PT,PT1,PT11,PT15,PT16,PT17,PT18,PT19,PT1A,PT1B,PT1C,PT1D,PT2,PT20,PT3,PT30,RO,RO1,RO11,RO12,RO2,RO21,RO22,RO3,RO31,RO32,RO4,RO41,RO42,SI,SI0,SI03,SI04,SK,SK0,SK01,SK02,SK03,SK04,FI,FI1,FI19,FI1B,FI1C,FI1D,FI2,FI20,SE,SE1,SE11,SE12,SE2,SE21,SE22,SE23,SE3,SE31,SE32,SE33',\n",
        "        'c[TIME_PERIOD]': '2024,2023,2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,1999,1998,1997,1996,1995,1994,1993,1992,1991,1990',\n",
        "        'compress': 'true',\n",
        "        'format': 'tsv'\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        print(\"  Downloading from demo_r_d2jan (SDMX API - TSV format)...\")\n",
        "        response = requests.get(tsv_url, params=tsv_params, timeout=120)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        # Read TSV data\n",
        "        # The first column contains dimensions: freq,unit,sex,age,geo\\TIME_PERIOD\n",
        "        # Subsequent columns are years\n",
        "        df = pd.read_csv(io.StringIO(response.text), sep='\\t', low_memory=False, dtype=str)\n",
        "        \n",
        "        # Get the first column name (contains dimensions)\n",
        "        first_col = df.columns[0]\n",
        "        \n",
        "        # Split first column into dimension columns\n",
        "        # Format: freq,unit,sex,age,geo\\TIME_PERIOD\n",
        "        df[['freq', 'unit', 'sex', 'age', 'geo']] = df[first_col].str.split(',', expand=True, n=4)\n",
        "        \n",
        "        # Clean geo column (remove \\TIME_PERIOD if present)\n",
        "        df['geo'] = df['geo'].str.replace('\\\\TIME_PERIOD', '', regex=False)\n",
        "        \n",
        "        # Filter to required dimensions\n",
        "        df = df[\n",
        "            (df['freq'] == 'A') &\n",
        "            (df['unit'] == 'NR') &\n",
        "            (df['sex'] == 'T') &\n",
        "            (df['age'] == 'TOTAL')\n",
        "        ]\n",
        "        \n",
        "        # Get year columns (all columns except dimension columns)\n",
        "        dim_cols = ['freq', 'unit', 'sex', 'age', 'geo', first_col]\n",
        "        year_cols = [col for col in df.columns if col not in dim_cols]\n",
        "        \n",
        "        if not year_cols:\n",
        "            raise ValueError(\"Could not find year columns in demo_r_d2jan data\")\n",
        "        \n",
        "        # Melt to long format\n",
        "        tidy = df.melt(\n",
        "            id_vars=['geo'],\n",
        "            value_vars=year_cols,\n",
        "            var_name='year',\n",
        "            value_name='population'\n",
        "        )\n",
        "        \n",
        "        # Clean up\n",
        "        tidy['year'] = tidy['year'].astype(int)\n",
        "        tidy['geo'] = tidy['geo'].str.strip().str.upper()\n",
        "        \n",
        "        # Replace missing indicators (:, b, etc.) with NaN\n",
        "        tidy['population'] = pd.to_numeric(tidy['population'], errors='coerce')\n",
        "        tidy = tidy.dropna(subset=['population'])\n",
        "        tidy['population'] = tidy['population'].astype(float)\n",
        "        \n",
        "        # Filter to desired year range\n",
        "        tidy = tidy[(tidy['year'] >= 2000) & (tidy['year'] <= 2024)]\n",
        "        \n",
        "        return tidy[['geo', 'year', 'population']]\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Error downloading demo_r_d2jan (TSV): {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "def _try_alternative_datasets() -> dict:\n",
        "    \"\"\"\n",
        "    Try multiple Eurostat population datasets to find historical data.\n",
        "    Returns a dictionary with dataset availability information.\n",
        "    \"\"\"\n",
        "    datasets = ['demo_r_d2jan', 'demo_r_pjangrp3', 'demo_r_pjangrp2', 'demo_r_pjangrp1']\n",
        "    results = {}\n",
        "    \n",
        "    # Try demo_r_d2jan first (SDMX API)\n",
        "    print(\"  Trying demo_r_d2jan (SDMX API)...\")\n",
        "    try:\n",
        "        df_d2jan = _download_demo_r_d2jan()\n",
        "        if not df_d2jan.empty:\n",
        "            years = sorted(df_d2jan['year'].unique())\n",
        "            nuts2_codes = df_d2jan[df_d2jan['geo'].str.len() == 4]['geo'].unique()\n",
        "            results['demo_r_d2jan'] = {\n",
        "                'available_years': (min(years), max(years)),\n",
        "                'nuts2_count': len(nuts2_codes),\n",
        "                'has_2000_2013': min(years) <= 2000 and max(years) >= 2013,\n",
        "                'success': True,\n",
        "                'dataframe': df_d2jan\n",
        "            }\n",
        "            print(f\"    ✓ demo_r_d2jan: years {min(years)}-{max(years)}, {len(nuts2_codes)} NUTS2 regions\")\n",
        "        else:\n",
        "            results['demo_r_d2jan'] = {'error': 'Empty dataframe', 'success': False}\n",
        "    except Exception as e:\n",
        "        results['demo_r_d2jan'] = {'error': str(e), 'success': False}\n",
        "    \n",
        "    # Try other datasets using eurostat package\n",
        "    for dataset_code in ['demo_r_pjangrp3', 'demo_r_pjangrp2', 'demo_r_pjangrp1']:\n",
        "        try:\n",
        "            print(f\"  Trying {dataset_code}...\")\n",
        "            df = get_data_df(dataset_code, flags=True)\n",
        "            value_cols = [c for c in df.columns if c.endswith(\"_value\")]\n",
        "            if not value_cols:\n",
        "                results[dataset_code] = {'error': 'No value columns found'}\n",
        "                continue\n",
        "                \n",
        "            years = [int(c.replace(\"_value\", \"\")) for c in value_cols]\n",
        "            min_year, max_year = min(years), max(years)\n",
        "            \n",
        "            # Check NUTS2 availability\n",
        "            if 'geo\\\\TIME_PERIOD' in df.columns:\n",
        "                nuts2_codes = df[df['geo\\\\TIME_PERIOD'].str.len() == 4]['geo\\\\TIME_PERIOD'].unique()\n",
        "                results[dataset_code] = {\n",
        "                    'available_years': (min_year, max_year),\n",
        "                    'nuts2_count': len(nuts2_codes),\n",
        "                    'has_2000_2013': min_year <= 2000 and max_year >= 2013,\n",
        "                    'success': True\n",
        "                }\n",
        "            else:\n",
        "                results[dataset_code] = {'error': 'No geo column found'}\n",
        "        except Exception as e:\n",
        "            results[dataset_code] = {'error': str(e), 'success': False}\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def _download_population(filter_nuts2: bool = False, try_alternatives: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Download population data from Eurostat and return tidy dataframe.\n",
        "    \n",
        "    Attempts to download data for years 2000-2024. Tries multiple datasets:\n",
        "    1. demo_r_d2jan (SDMX API) - may have historical NUTS2 data\n",
        "    2. demo_r_pjangrp3, demo_r_pjangrp2, demo_r_pjangrp1 (eurostat package)\n",
        "    \n",
        "    Note: Historical data availability varies by region and NUTS level. Some years\n",
        "    (especially 2000-2013) may not be available at NUTS2 level for all regions.\n",
        "    \"\"\"\n",
        "    # Try alternative datasets first if requested\n",
        "    best_dataset = \"demo_r_pjangrp3\"\n",
        "    best_dataframe = None\n",
        "    \n",
        "    if try_alternatives:\n",
        "        print(\"Checking alternative Eurostat datasets for historical data...\")\n",
        "        alternatives = _try_alternative_datasets()\n",
        "        \n",
        "        # Find dataset with best coverage (has 2000-2013 and NUTS2 data)\n",
        "        for dataset_code, info in alternatives.items():\n",
        "            if info.get('success') and info.get('has_2000_2013') and info.get('nuts2_count', 0) > 0:\n",
        "                best_dataset = dataset_code\n",
        "                # If demo_r_d2jan, use the pre-downloaded dataframe\n",
        "                if dataset_code == 'demo_r_d2jan' and 'dataframe' in info:\n",
        "                    best_dataframe = info['dataframe']\n",
        "                print(f\"  ✓ Found {dataset_code} with years {info['available_years']} and {info['nuts2_count']} NUTS2 regions\")\n",
        "                break\n",
        "        else:\n",
        "            print(f\"  ⚠ No alternative dataset found with 2000-2013 NUTS2 data, using {best_dataset}\")\n",
        "    \n",
        "    # If we have a pre-downloaded dataframe (from demo_r_d2jan), use it\n",
        "    if best_dataframe is not None:\n",
        "        tidy = best_dataframe.copy()\n",
        "    else:\n",
        "        # Download from best available dataset using eurostat package\n",
        "        df = get_data_df(best_dataset, flags=True)\n",
        "        value_cols = [c for c in df.columns if c.endswith(\"_value\")]\n",
        "        tidy = df.melt(\n",
        "            id_vars=[\"freq\", \"sex\", \"unit\", \"age\", \"geo\\\\TIME_PERIOD\"],\n",
        "            value_vars=value_cols,\n",
        "            var_name=\"year_raw\",\n",
        "            value_name=\"population\",\n",
        "        )\n",
        "        tidy[\"year\"] = tidy[\"year_raw\"].str.replace(\"_value\", \"\", regex=False).astype(int)\n",
        "        tidy = tidy.rename(columns={\"geo\\\\TIME_PERIOD\": \"geo\"})\n",
        "        tidy = tidy[\n",
        "            (tidy[\"freq\"] == \"A\")\n",
        "            & (tidy[\"sex\"] == \"T\")\n",
        "            & (tidy[\"unit\"] == \"NR\")\n",
        "            & (tidy[\"age\"] == \"TOTAL\")\n",
        "        ]\n",
        "        tidy = tidy[[\"geo\", \"year\", \"population\"]]\n",
        "        tidy[\"geo\"] = tidy[\"geo\"].str.strip().str.upper()\n",
        "        tidy = tidy.dropna(subset=[\"population\"])\n",
        "        tidy[\"population\"] = tidy[\"population\"].astype(float)\n",
        "        \n",
        "        # Filter to desired year range (2000-2024) if available\n",
        "        tidy = tidy[(tidy[\"year\"] >= 2000) & (tidy[\"year\"] <= 2024)]\n",
        "    \n",
        "    # Optional: Filter to NUTS2 level only (4 characters) if requested\n",
        "    # By default, we preserve all geographic levels for maximum flexibility\n",
        "    if filter_nuts2:\n",
        "        def _is_valid_nuts2(code: str) -> bool:\n",
        "            if not isinstance(code, str):\n",
        "                code = str(code)\n",
        "            return len(code.strip()) == 4\n",
        "        tidy = tidy[tidy[\"geo\"].apply(_is_valid_nuts2)]\n",
        "    \n",
        "    return tidy\n",
        "\n",
        "def load_population(force_refresh: bool = False, filter_nuts2: bool = False, try_alternatives: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load population data, processing TSV file if available, otherwise downloading from API.\n",
        "    \n",
        "    Parameters:\n",
        "    - force_refresh: If True, re-process/download even if cached file exists\n",
        "    - filter_nuts2: If True, filter to NUTS2 level only (4-character codes)\n",
        "    - try_alternatives: If True, try alternative Eurostat datasets for historical data (only if TSV not available)\n",
        "    \"\"\"\n",
        "    population_path = PROJECT_ROOT / \"data\" / \"processed\" / \"population_nuts2.parquet\"\n",
        "    tsv_path = PROJECT_ROOT / \"data\" / \"raw\" / \"population\" / \"demo_r_d2jan_tabular.tsv\"\n",
        "    \n",
        "    # Check if cached parquet exists and we're not forcing refresh\n",
        "    if population_path.exists() and not force_refresh:\n",
        "        df = pd.read_parquet(population_path)\n",
        "        # Apply filtering if requested and data exists\n",
        "        if filter_nuts2:\n",
        "            def _is_valid_nuts2(code: str) -> bool:\n",
        "                if not isinstance(code, str):\n",
        "                    code = str(code)\n",
        "                return len(code.strip()) == 4\n",
        "            df = df[df[\"geo\"].apply(_is_valid_nuts2)]\n",
        "        return df\n",
        "\n",
        "    # Try to process TSV file first (if available)\n",
        "    if tsv_path.exists():\n",
        "        print(\"Found TSV file, processing...\")\n",
        "        try:\n",
        "            tidy = _process_population_tsv(tsv_path, filter_nuts2=filter_nuts2)\n",
        "            population_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            tidy.to_parquet(population_path, index=False)\n",
        "            return tidy\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ Error processing TSV file: {e}\")\n",
        "            print(\"  Falling back to API download...\")\n",
        "    else:\n",
        "        print(\"TSV file not found, downloading from API...\")\n",
        "    \n",
        "    # Fallback to API download\n",
        "    tidy = _download_population(filter_nuts2=filter_nuts2, try_alternatives=try_alternatives)\n",
        "    population_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    tidy.to_parquet(population_path, index=False)\n",
        "    return tidy\n",
        "\n",
        "# Load population data (preserving all geographic levels)\n",
        "# Set try_alternatives=True to check for historical data in other Eurostat datasets\n",
        "population = load_population(force_refresh=False, filter_nuts2=False, try_alternatives=True)\n",
        "print(f\"✓ Loaded {len(population):,} population records\")\n",
        "print(f\"  Years: {population['year'].min()} - {population['year'].max()}\")\n",
        "print(f\"  Unique geographic codes: {population['geo'].nunique()}\")\n",
        "print(f\"  Geographic code length distribution:\")\n",
        "print(f\"    {population['geo'].str.len().value_counts().sort_index().to_dict()}\")\n",
        "\n",
        "# Check NUTS2 coverage\n",
        "nuts2_data = population[population['geo'].str.len() == 4]\n",
        "if len(nuts2_data) > 0:\n",
        "    nuts2_years = sorted(nuts2_data['year'].unique())\n",
        "    print(f\"\\n  NUTS2 data available for years: {nuts2_years[0]} - {nuts2_years[-1]} ({len(nuts2_years)} years)\")\n",
        "    if nuts2_years[0] > 2000:\n",
        "        print(f\"  ⚠ WARNING: NUTS2 data starts from {nuts2_years[0]}, not 2000\")\n",
        "        print(f\"     Consider using NUTS1 interpolation or accepting NULL values for earlier years\")\n",
        "\n",
        "population.head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
